"""add glacier and analysis

Revision ID: cb6b5a832aa5
Revises: 037e08bdaff9
Create Date: 2025-12-10 20:56:23.543930

"""

from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from geoalchemy2 import Geometry
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = "cb6b5a832aa5"
down_revision: Union[str, Sequence[str], None] = "037e08bdaff9"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_geospatial_table(
        "glacier",
        sa.Column("glacier_id", sa.String(), nullable=False),
        sa.Column("project_id", sa.String(), nullable=True),
        sa.Column("name", sa.String(), nullable=True),
        sa.Column(
            "geometry",
            Geometry(
                geometry_type="MULTIPOLYGON",
                srid=4326,
                dimension=2,
                spatial_index=False,
                from_text="ST_GeomFromEWKT",
                name="geometry",
                nullable=False,
            ),
            nullable=False,
        ),
        sa.Column("area_m2", sa.Float(), nullable=True),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.ForeignKeyConstraint(
            ["project_id"],
            ["project.project_id"],
        ),
        sa.PrimaryKeyConstraint("glacier_id"),
    )
    op.create_geospatial_index(
        "idx_glacier_geometry",
        "glacier",
        ["geometry"],
        unique=False,
        postgresql_using="gist",
        postgresql_ops={},
    )
    op.create_index(
        op.f("ix_glacier_project_id"), "glacier", ["project_id"], unique=False
    )
    op.create_table(
        "glacier_analysis_result",
        sa.Column("id", sa.String(), nullable=False),
        sa.Column("scene_id", sa.String(), nullable=True),
        sa.Column("analysis_date", sa.DateTime(), nullable=False),
        sa.Column("snow_area_m2", sa.Float(), nullable=False),
        sa.Column("total_glacier_snow_area_m2", sa.Float(), nullable=False),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.ForeignKeyConstraint(
            ["scene_id"],
            ["scene.scene_id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        op.f("ix_glacier_analysis_result_scene_id"),
        "glacier_analysis_result",
        ["scene_id"],
        unique=False,
    )
    op.create_table(
        "glacier_snow_data",
        sa.Column("id", sa.String(), nullable=False),
        sa.Column("analysis_id", sa.String(), nullable=True),
        sa.Column("glacier_id", sa.String(), nullable=True),
        sa.Column("scene_id", sa.String(), nullable=True),
        sa.Column("snow_area_m2", sa.Integer(), nullable=True),
        sa.Column("snowline_elevation_m", sa.Integer(), nullable=True),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.ForeignKeyConstraint(
            ["analysis_id"],
            ["glacier_analysis_result.id"],
        ),
        sa.ForeignKeyConstraint(
            ["glacier_id"],
            ["glacier.glacier_id"],
        ),
        sa.ForeignKeyConstraint(
            ["scene_id"],
            ["scene.scene_id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        op.f("ix_glacier_snow_data_analysis_id"),
        "glacier_snow_data",
        ["analysis_id"],
        unique=False,
    )
    op.create_index(
        op.f("ix_glacier_snow_data_glacier_id"),
        "glacier_snow_data",
        ["glacier_id"],
        unique=False,
    )
    op.create_index(
        op.f("ix_glacier_snow_data_scene_id"),
        "glacier_snow_data",
        ["scene_id"],
        unique=False,
    )
    op.alter_column("scene", "project_id", existing_type=sa.VARCHAR(), nullable=True)
    op.alter_column("scene", "stac_href", existing_type=sa.VARCHAR(), nullable=True)
    op.alter_column(
        "scene", "acquisition_date", existing_type=postgresql.TIMESTAMP(), nullable=True
    )
    op.alter_column(
        "scene",
        "status",
        existing_type=postgresql.ENUM(
            "discovered",
            "queued_for_download",
            "downloading",
            "downloaded",
            "failed_download",
            "queued_for_processing",
            "processing",
            "processed",
            "failed_processing",
            name="scenestatusenum",
        ),
        type_=sa.Enum(
            "discovered",
            "queued_for_download",
            "downloading",
            "downloaded",
            "failed_download",
            "queued_for_processing",
            "processing",
            "processed",
            "failed_processing",
            name="scenestatusenum",
            native_enum=False,
        ),
        existing_nullable=False,
    )
    op.alter_column(
        "scene", "attempts_download", existing_type=sa.INTEGER(), nullable=True
    )
    op.alter_column(
        "scene", "attempts_processing", existing_type=sa.INTEGER(), nullable=True
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column(
        "scene", "attempts_processing", existing_type=sa.INTEGER(), nullable=False
    )
    op.alter_column(
        "scene", "attempts_download", existing_type=sa.INTEGER(), nullable=False
    )
    op.alter_column(
        "scene",
        "status",
        existing_type=sa.Enum(
            "discovered",
            "queued_for_download",
            "downloading",
            "downloaded",
            "failed_download",
            "queued_for_processing",
            "processing",
            "processed",
            "failed_processing",
            name="scenestatusenum",
            native_enum=False,
        ),
        type_=postgresql.ENUM(
            "discovered",
            "queued_for_download",
            "downloading",
            "downloaded",
            "failed_download",
            "queued_for_processing",
            "processing",
            "processed",
            "failed_processing",
            name="scenestatusenum",
        ),
        existing_nullable=False,
    )
    op.alter_column(
        "scene",
        "acquisition_date",
        existing_type=postgresql.TIMESTAMP(),
        nullable=False,
    )
    op.alter_column("scene", "stac_href", existing_type=sa.VARCHAR(), nullable=False)
    op.alter_column("scene", "project_id", existing_type=sa.VARCHAR(), nullable=False)

    op.drop_index(op.f("ix_glacier_snow_data_scene_id"), table_name="glacier_snow_data")
    op.drop_index(
        op.f("ix_glacier_snow_data_glacier_id"), table_name="glacier_snow_data"
    )
    op.drop_index(
        op.f("ix_glacier_snow_data_analysis_id"), table_name="glacier_snow_data"
    )
    op.drop_table("glacier_snow_data")
    op.drop_index(
        op.f("ix_glacier_analysis_result_scene_id"),
        table_name="glacier_analysis_result",
    )
    op.drop_table("glacier_analysis_result")
    op.drop_index(op.f("ix_glacier_project_id"), table_name="glacier")
    op.drop_geospatial_index(
        "idx_glacier_geometry",
        table_name="glacier",
        postgresql_using="gist",
        column_name="geometry",
    )
    op.drop_geospatial_table("glacier")
    # ### end Alembic commands ###
